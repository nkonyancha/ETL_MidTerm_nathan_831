<<<<<<< HEAD
=======
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3aefce48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21825a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the raw and incremental data from CSV files\n",
    "rawdata = pd.read_csv(r'data\\raw_data.csv')\n",
    "incremented = pd.read_csv(r'data\\incremental_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af722ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     NaN\n",
      "1     NaN\n",
      "2     NaN\n",
      "3     NaN\n",
      "4     NaN\n",
      "5    True\n",
      "6     NaN\n",
      "7     NaN\n",
      "8     NaN\n",
      "9     NaN\n",
      "dtype: object\n",
      "    order_id customer_name  product  quantity  unit_price  order_date region\n",
      "0          1         Diana   Tablet       NaN       500.0  2024-01-20  South\n",
      "1          2           Eve   Laptop       NaN         NaN  2024-04-29  North\n",
      "2          3       Charlie   Laptop       2.0       250.0  2024-01-08    NaN\n",
      "3          4           Eve   Laptop       2.0       750.0  2024-01-07   West\n",
      "4          5           Eve   Tablet       3.0         NaN  2024-03-07  South\n",
      "6          7       Charlie  Monitor       2.0       750.0  2024-02-02   West\n",
      "7          8       Charlie   Laptop       3.0         NaN  2024-02-17    NaN\n",
      "8          9       Charlie  Monitor       NaN       750.0  2024-03-16   West\n",
      "9         10           Eve  Monitor       1.0       500.0  2024-02-28  North\n",
      "10        11           NaN  Monitor       3.0       750.0  2024-04-24   West\n"
     ]
    }
   ],
   "source": [
    "#cleaning the data\n",
    "duplicates=rawdata.duplicated()\n",
    "print(duplicates.where(duplicates == True).head(10))\n",
    "#removing duplicates\n",
    "rawdata = rawdata.drop_duplicates(subset=['order_id'])\n",
    "print(rawdata.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86382868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id          0\n",
      "customer_name     1\n",
      "product           0\n",
      "quantity         26\n",
      "unit_price       35\n",
      "order_date        1\n",
      "region           25\n",
      "dtype: int64\n",
      "product\n",
      "Laptop     383.333333\n",
      "Monitor    531.250000\n",
      "Phone      531.250000\n",
      "Tablet     530.000000\n",
      "Name: unit_price, dtype: float64\n",
      "order_id          0\n",
      "customer_name     1\n",
      "product           0\n",
      "quantity          0\n",
      "unit_price        0\n",
      "order_date        1\n",
      "region           17\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#handling missing values\n",
    "print(rawdata.isnull().sum())\n",
    "products=rawdata['product'].unique()\n",
    "#getting mean price of products\n",
    "mean_price = rawdata.groupby('product')['unit_price'].mean()\n",
    "print(mean_price)\n",
    "#filling missing values with mean price\n",
    "rawdata['unit_price'] = rawdata['unit_price'].fillna(rawdata['product'].map(mean_price))\n",
    "# removing rows with missing values in 'quantity' column\n",
    "rawdata = rawdata.dropna(subset=['quantity'])\n",
    "#checking if there are still missing values\n",
    "print(rawdata.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150167b1",
   "metadata": {},
   "source": [
    "In the above code block i have performed a number of transformations, one i have replaced null values in the unit price column by the mean unit price for that product, i have also dropped rows with a null quantity value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e93b15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    order_id  product  quantity  unit_price  order_date region  total_price\n",
      "2          3   Laptop       2.0  250.000000  2024-01-08    NaN        500.0\n",
      "3          4   Laptop       2.0  750.000000  2024-01-07   West       1500.0\n",
      "4          5   Tablet       3.0  530.000000  2024-03-07  South       1590.0\n",
      "6          7  Monitor       2.0  750.000000  2024-02-02   West       1500.0\n",
      "7          8   Laptop       3.0  383.333333  2024-02-17    NaN       1150.0\n",
      "9         10  Monitor       1.0  500.000000  2024-02-28  North        500.0\n",
      "10        11  Monitor       3.0  750.000000  2024-04-24   West       2250.0\n",
      "11        12   Tablet       2.0  750.000000  2024-03-26   East       1500.0\n",
      "12        13   Tablet       1.0  750.000000  2024-04-28   West        750.0\n",
      "13        14   Tablet       1.0  530.000000  2024-01-22  South        530.0\n"
     ]
    }
   ],
   "source": [
    "#getting the total price per order\n",
    "rawdata['total_price'] = rawdata['unit_price'] * rawdata['quantity']\n",
    "\n",
    "#dropping unnecessary columns\n",
    "rawdata = rawdata.drop(columns=['customer_name'])\n",
    "print(rawdata.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724c67bd",
   "metadata": {},
   "source": [
    "Here i perfomed some more transformations\n",
    "\n",
    "-created a new row that calculated the total price of the order this makes analysing the data set easier as total price is an important analysis point. \n",
    "\n",
    "-I have also dropped columns such as column_name as it is unessecary for analysis and the null values make it impossible to accurately change the column to customer_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f0b8969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sale_tier\n",
      "Bronze    34\n",
      "Silver    24\n",
      "Gold      10\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "avg=rawdata['total_price'].mean()\n",
    "min=rawdata['total_price'].min()\n",
    "max=rawdata['total_price'].max()\n",
    "#creating customer tiers according to total price\n",
    "\n",
    "tiers = [min,avg,2000,max]\n",
    "tier_labels = ['Bronze', 'Silver', 'Gold']\n",
    "rawdata['sale_tier'] = pd.cut(rawdata['total_price'], bins=tiers, labels=tier_labels)\n",
    "print(rawdata['sale_tier'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d31c74",
   "metadata": {},
   "source": [
    "In this block i have created a new column called sale_tier that divides sales into different tiers being Bronze, Silver, Gold according to total price. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ceedaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding cleaned data to new csv file\n",
    "rawdata.to_csv(r'transformed\\transformed_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9750ce0",
   "metadata": {},
   "source": [
    "DOING THE SAME TO INCREMENTAL DATA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "488a69ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   order_id customer_name product  quantity  unit_price  order_date   region\n",
      "0       101         Alice  Laptop       NaN       900.0  2024-05-09  Central\n",
      "1       102           NaN  Laptop       1.0       300.0  2024-05-07  Central\n",
      "2       103           NaN  Laptop       1.0       600.0  2024-05-04  Central\n",
      "3       104           NaN  Tablet       NaN       300.0  2024-05-26  Central\n",
      "4       105         Heidi  Tablet       2.0       600.0  2024-05-21    North\n",
      "5       106           NaN  Laptop       2.0       600.0  2024-05-18  Central\n",
      "6       107           NaN  Tablet       1.0       600.0  2024-05-13  Central\n",
      "7       108           NaN  Laptop       NaN       600.0  2024-05-11      NaN\n",
      "8       109         Grace  Laptop       2.0       600.0  2024-05-29  Central\n",
      "9       110         Heidi   Phone       NaN       900.0  2024-05-24      NaN\n",
      "order_id      0\n",
      "product       0\n",
      "quantity      0\n",
      "unit_price    0\n",
      "order_date    0\n",
      "region        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(incremented.head(10))\n",
    "#handling missing values in incremental data\n",
    "mean_price = incremented.groupby('product')['unit_price'].mean()\n",
    "incremented['unit_price'] = incremented['unit_price'].fillna(incremented['product'].map(mean_price))\n",
    "# removing rows with missing values in 'quantity' column\n",
    "incremented = incremented.dropna(subset=['quantity'])\n",
    "#converting order_date to datetime\n",
    "incremented['order_date'] = pd.to_datetime(incremented['order_date'], format='%Y-%m-%d')\n",
    "incremented.head(10)\n",
    "#removing unnecessary columns\n",
    "incremented = incremented.drop(columns=['customer_name'])\n",
    "print(incremented.isnull().sum())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e31c131",
   "metadata": {},
   "source": [
    "In the above code block, i have performed the following transformations.\n",
    "\n",
    "-Populated unit price column with mean unit price for each product for ease of analysis\n",
    "\n",
    "-Dropped any rows with a null quantity value, cant populate with mean as this would return highly inaccurate analytic results\n",
    "\n",
    "-Changed order_date column to be date time format as this would ease sorting by date while perfoming analysis\n",
    "\n",
    "-Dropped customer_name column as it is unessecary for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a60b3ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300.0\n",
      "850.0\n",
      "1200.0\n"
     ]
    }
   ],
   "source": [
    "#calculating total price for incremental data  \n",
    "incremented['total_price'] = incremented['unit_price'] * incremented['quantity']\n",
    "#adding customer tier to incremental data\n",
    "min=incremented['total_price'].min()\n",
    "print(min)\n",
    "avg=incremented['total_price'].mean()\n",
    "print(avg)\n",
    "max=incremented['total_price'].max()\n",
    "print(max)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e59026",
   "metadata": {},
   "source": [
    "Created a total price column by multiplying unit price by quantity as this would be a nessecary column during analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "daab8ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding incremental data to new csv file\n",
    "incremented.to_csv(r'transformed\\transformed_incremental.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
>>>>>>> 588f218 (Last Update)
